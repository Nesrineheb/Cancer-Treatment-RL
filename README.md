# RL Cancer Treatment ğŸ©º

## Description ğŸ“š

Le projet RL Cancer Treatment vise Ã  dÃ©velopper un systÃ¨me d'apprentissage par renforcement (RL) pour aider Ã  la prise de dÃ©cisions de traitement dans le contexte de la croissance tumorale. Il utilise l'apprentissage automatique pour optimiser les dÃ©cisions de traitement en modÃ©lisant la croissance tumorale et en prenant des dÃ©cisions basÃ©es sur cette modÃ©lisation.

## Objectifs ğŸ¯

Les principaux objectifs du projet sont les suivants :

1. CrÃ©er un environnement de simulation, CancerGrowthEnv, pour modÃ©liser la croissance tumorale.
2. ImplÃ©menter un agent RandomAgent pour prendre des dÃ©cisions de traitement.
3. ImplÃ©menter un agent DQN (Deep Q-Network) pour prendre des dÃ©cisions de traitement.
4. Personnaliser l'agent DQN pour amÃ©liorer ses performances dans l'environnement.
5. Ã‰tendre le projet Ã  un contexte multi-agent pour mieux modÃ©liser la situation mÃ©dicale rÃ©elle.
6. Personnaliser l'agent DQN vers une architecture double dans le contexte multi-agent pour amÃ©liorer les performances.

## Table des matiÃ¨res ğŸ—‚ï¸

- [Installation](#installation)
- [Structure du Projet](#structure-du-projet)
- [Contribuer](#contribuer)
- [Licence](#licence)

## Installation ğŸš€

Pour utiliser ce projet, suivez les Ã©tapes ci-dessous :

1. **CrÃ©er un environnement python ğŸ :**
   - Assurez-vous d'avoir Python (version 3.6 ou supÃ©rieure) installÃ©.
   - Installez `pip` (gestionnaire de packages Python).

2. **Clonez ce dÃ©pÃ´t ğŸ§¬ :**
   ```bash
   git clone https://github.com/votre_utilisateur/rl-cancer-treatment.git
   cd rl-cancer-treatment


Installez les dÃ©pendances requises ğŸ“¦ :
    pip install -r requirements.txt

   
 ## Structure du Projet ğŸ—ï¸

 Structure du Projet ğŸ—ï¸

1. CancerGrowthEnv ğŸ¥
est une implÃ©mentation d'un environnement Gym personnalisÃ©. Elle modÃ©lise la croissance d'une tumeur cancÃ©reuse et permet aux agents d'agir en choisissant de traiter ou de ne pas traiter la tumeur. Voici quelques dÃ©tails importants sur cette classe :

- **`__init__(self, num_agents=2)`** : Le constructeur de la classe permet de spÃ©cifier le nombre d'agents (par dÃ©faut Ã  2). Il dÃ©finit Ã©galement les espaces d'observation et d'action pour les agents.

- **`step(self, actions)`** : Cette mÃ©thode permet aux agents de prendre des actions en fonction des actions fournies en entrÃ©e. Elle calcule les rÃ©compenses pour chaque agent et dÃ©finit si l'Ã©pisode est terminÃ©.

- **`reset(self, verbose=True)`** : Cette mÃ©thode rÃ©initialise l'Ã©tat de l'environnement pour chaque agent. Si `verbose` est dÃ©fini sur True, elle affiche un message de rÃ©initialisation.


2. DQNAgent ğŸ¤–
La classe `DQNAgent` est un agent d'apprentissage profond par renforcement qui utilise un rÃ©seau de neurones pour prendre des dÃ©cisions dans l'environnement `CancerGrowthEnv`. Voici quelques dÃ©tails importants sur cette classe :

- **`__init__(self, state_size, action_size, verbose=0)`** : Le constructeur de la classe permet de spÃ©cifier la taille de l'Ã©tat et de l'action, ainsi qu'un paramÃ¨tre optionnel `verbose` pour le niveau de verbositÃ©.

- **`_build_model(self)`** : Cette mÃ©thode construit un modÃ¨le de rÃ©seau de neurones utilisÃ© par l'agent pour prendre des dÃ©cisions.

- **`remember(self, state, action, reward, next_state, done)`** : Cette mÃ©thode permet Ã  l'agent de mÃ©moriser l'expÃ©rience passÃ©e dans son buffer de mÃ©moire.

- **`act(self, state)`** : Cette mÃ©thode permet Ã  l'agent de choisir une action en fonction de l'Ã©tat actuel. Elle peut prendre en compte l'exploration en utilisant epsilon-greedy.

- **`replay(self)`** : Cette mÃ©thode permet Ã  l'agent d'apprendre Ã  partir de ses expÃ©riences passÃ©es en effectuant une mise Ã  jour du modÃ¨le.


3. Train ğŸš‚
La classe `Train` est responsable de l'entraÃ®nement des agents dans l'environnement `CancerGrowthEnv`. Elle coordonne les interactions entre les agents et l'environnement, gÃ¨re les rÃ©compenses et les mises Ã  jour des modÃ¨les. Voici quelques dÃ©tails importants sur cette classe :

- **`__init__(self, env, agents, num_episodes)`** : Le constructeur de la classe prend l'environnement, les agents et le nombre d'Ã©pisodes comme paramÃ¨tres.

- **`train(self)`** : Cette mÃ©thode exÃ©cute l'entraÃ®nement des agents sur un certain nombre d'Ã©pisodes. Elle gÃ¨re Ã©galement la sauvegarde du modÃ¨le prÃ©-entraÃ®nÃ© et des rÃ©compenses.
  
4. main ğŸš€
Le script principal `main.py` entraÃ®ne deux agents DQN dans l'environnement `CancerGrowthEnv` pour gÃ©rer la croissance tumorale.


## Contribuer ğŸ¤

Les contributions Ã  ce projet sont les bienvenues ! Pour contribuer, suivez ces Ã©tapes :

1. Forkez ce rÃ©fÃ©rentiel (repository) sur GitHub.
2. CrÃ©ez une branche (branch) pour votre contribution : `git checkout -b ma-contribution`
3. Faites vos modifications et committez-les : `git commit -m 'Ajout de nouvelles fonctionnalitÃ©s'`
4. Poussez vos modifications sur votre fork : `git push origin ma-contribution`
5. CrÃ©ez une Pull Request sur GitHub Ã  partir de votre fork.

Nous examinerons vos contributions avec attention et les intÃ©grerons au projet si elles sont pertinentes.


## Licence ğŸ“„

- [HEBBADJ NESRINE](https://github.com/Nesrineheb)






